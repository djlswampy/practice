{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82653b5e-3e64-467b-bee0-36516f8bb5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_076f734ea6ed70f00068dc0e103e18819493388269bb4e15e3', created_at=1759251984.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_076f734ea6ed70f00068dc0e10ea648194973abaea66dd55fb', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_076f734ea6ed70f00068dc0e16b4fc8194acf7c922e3448dca', content=[ResponseOutputText(annotations=[], text='ì˜›ë‚  ì•„ì£¼ ê³ ìš´ ìˆ² ì†ì— ì€ë¹› ë¿”ì„ ê°€ì§„ ì‘ì€ ìœ ë‹ˆì½˜ì´ ì‚´ì•˜ì–´ìš”. ë‹¬ë¹›ì´ ë¹„ì¶”ëŠ” ë°¤ë§ˆë‹¤ ê·¸ëŠ” ë‹¤ì •í•œ ì†ì‚­ì„ìœ¼ë¡œ ê¸¸ ìƒì€ ì´ë“¤ì˜ ê¿ˆì„ ì°¾ì•„ ì£¼ì—ˆì–´ìš”. ì•„ì´ë“¤ì´ ì°½ë¬¸ì„ ë‹«ê³  ì ë“¤ë©´, ìœ ë‹ˆì½˜ì€ ë³„ë¹›ìœ¼ë¡œ ê¸¸ì„ ë¹„ì¶° ì£¼ë©° í¸ì•ˆí•œ ì ì„ ì„ ë¬¼í•œë‹µë‹ˆë‹¤.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=1249, output_tokens_details=OutputTokensDetails(reasoning_tokens=1152), total_tokens=1267), user=None, billing={'payer': 'developer'}, store=True)\n"
     ]
    }
   ],
   "source": [
    "# OpenAI clientë¥¼ í†µí•´ llm í˜¸ì¶œ\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-5-nano\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn in korean\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75436d37-35e1-4867-a505-b9a34dfbabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë­ì²´ì¸ì—ì„œ ì œê³µí•˜ëŠ” ì˜¤í”ˆAI LLM ë˜í¼ë¥¼ í†µí•œ llm í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b06ea18c-376d-45fe-8d9a-b8d71ca60b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ì„œìš¸ ì…ë‹ˆë‹¤\\n\\nì„œìš¸ì€ í•œêµ­ì˜ ì •ì¹˜, ê²½ì œ, ë¬¸í™” ì¤‘ì‹¬ì§€ë¡œì„œ ë§ì€ ì¸êµ¬ì™€ ì—­ì‚¬ì ì¸ ê°€ì¹˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì˜ ì£¼ìš” ê´€ê´‘ì§€ ì¤‘ í•˜ë‚˜ì´ë©°, ì „ ì„¸ê³„ì—ì„œë„ ìœ ëª…í•œ ë„ì‹œì…ë‹ˆë‹¤. ì„œìš¸ì—ëŠ” í•œêµ­ì˜ ì „í†µê³¼ í˜„ëŒ€ê°€ ê³µì¡´í•˜ëŠ” ë‹¤ì–‘í•œ ê´€ê´‘ì§€, ë¨¹ê±°ë¦¬, ì‡¼í•‘ ëª…ì†Œê°€ ìˆì–´ì„œ ë§¤ë…„ ë§ì€ ê´€ê´‘ê°ë“¤ì´ ì°¾ì•„ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì„œìš¸ì€ êµ­ì œì ì¸ ë„ì‹œë¡œì„œ ì—¬ëŸ¬ ë‚˜ë¼ì™€ì˜ êµë¥˜ì™€ ë¬¸í™”ì  ë‹¤ì–‘ì„±ì„ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ê³³ì…ë‹ˆë‹¤. í•œêµ­ì˜ ìˆ˜ë„ì¸ ì„œìš¸ì€ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ë³€í™”í•˜ëŠ” ëª¨ìŠµì„ ë³´ì—¬ì£¼ë©°, ì „ ì„¸ê³„ì—ì„œë„ ì£¼ëª©ë°›ëŠ” ë„ì‹œê°€ ë˜ê³ '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê¸°ë³¸ LLM í˜¸ì¶œ\n",
    "\n",
    "from langchain_openai.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model = OpenAI(model = 'gpt-3.5-turbo-instruct')\n",
    "\n",
    "model.invoke('í•œêµ­ì˜ ìˆ˜ë„ëŠ” ')\n",
    "# print(\"result: \" + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94873dab-eb87-4c5c-b497-c86e50767160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 12, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLYcAQm6nmTX9y7mB2BB4rubmlo6a', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--16d03d2b-1f14-4c8d-ab62-5b4108b60ca0-0', usage_metadata={'input_tokens': 12, 'output_tokens': 21, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat model í˜¸ì¶œ\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI() # gpt-3.5-turbo-0125 (ChatOpenAIì˜ ê¸°ë³¸ ëª¨ë¸) ì‚¬ìš©ì´í•´\n",
    "prompt = [HumanMessage('í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')]\n",
    "model.invoke(prompt)\n",
    "\n",
    "# print(\"result: \" + result) ---> error. resultì˜ íƒ€ì…ì´ strì´ ì•„ë‹ˆë¼ AIMessage ê°ì²´ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d771c39-e0b6-40d8-888b-67e28de6d697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ™‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 12, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLYdCni4liWHrbhmSqZD7bVgAsGu9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c920ae64-078b-4a8a-929a-63ff9c2ee4b9-0', usage_metadata={'input_tokens': 12, 'output_tokens': 22, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strì„ ë„£ìœ¼ë©´ LangChainì´ ìë™ìœ¼ë¡œ HumanMessageë¡œ ë³€í™˜\n",
    "model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "# ë‚´ë¶€ì ìœ¼ë¡œ ì´ë ‡ê²Œ ë³€í™˜ë¨ â†“\n",
    "# model.invoke([HumanMessage(\"ì•ˆë…•í•˜ì„¸ìš”\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "211ace22-dece-4ae8-978b-af401671163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„œìš¸ì…ë‹ˆë‹¤!!!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "system_msg = SystemMessage(\n",
    "    '''ë‹¹ì‹ ì€ ë¬¸ì¥ ëì— ëŠë‚Œí‘œ ì„¸ ê°œë¥¼ ë¶™ì—¬ ëŒ€ë‹µí•˜ëŠ” ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'''\n",
    ")\n",
    "human_msg = HumanMessage('í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')\n",
    "\n",
    "ai_msg = model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "877371ab-0b04-4d73-a0a8-a244142210de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ê°œë°œìë“¤ì€ Hugging Faceì˜ `transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ê±°ë‚˜, `openai` ë° `cohere` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ OpenAIì™€ Cohereì˜ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  ë™ì  ì…ë ¥ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì†ì‰½ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template('''ì•„ë˜ ì‘ì„±í•œ ì»¨í…ìŠ¤íŠ¸(Context)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ\n",
    "    ì§ˆë¬¸(Question)ì— ëŒ€ë‹µí•˜ì„¸ìš”. ì œê³µëœ ì •ë³´ë¡œ ëŒ€ë‹µí•  ìˆ˜ ì—†ëŠ” ì§ˆë¬¸ì´ë¼ë©´ \"ëª¨ë¥´ê² ì–´ìš”.\" ë¼ê³  ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: ''')\n",
    "\n",
    "prompt = template.invoke({\n",
    "    'context': '''ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì˜ ìµœì‹  ë°œì „ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.\n",
    "    ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ë” ì‘ì€ ëª¨ë¸ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©°, NLP ê¸°ëŠ¥ì„ ê°–ì¶˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” ê°œë°œìë“¤ì—ê²Œ\n",
    "    ë§¤ìš° ì¤‘ìš”í•œ ë„êµ¬ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ê°œë°œìë“¤ì€ Hugging Faceì˜ `transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼\n",
    "    í™œìš©í•˜ê±°ë‚˜, `openai` ë° `cohere` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ OpenAIì™€ Cohereì˜ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬\n",
    "    ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    ''',\n",
    "    'question': 'ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ì–´ë””ì„œ ì œê³µí•˜ë‚˜ìš”?'\n",
    "})\n",
    "\n",
    "model = OpenAI()\n",
    "model.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1c3f332-c161-45dc-bb02-fd54335193ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nê¹€ì² ìˆ˜'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template('''Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Answer: ''')\n",
    "\n",
    "prompt = template.invoke({\n",
    "    'context': 'ë‚´ì´ë¦„ì€ ê¹€ì² ìˆ˜!',\n",
    "    'question': 'ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ??'\n",
    "})\n",
    "\n",
    "model = OpenAI()\n",
    "model.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a19684-cada-4d14-b727-6b0c0c7ff501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
